13/08/19 12:29:54 INFO util.HadoopUtil: resolving application jar from found main method on: impatient.Main
13/08/19 12:29:54 INFO planner.HadoopPlanner: using application jar: /home/fs111/code/concurrent/Impatient/part3/./build/libs/impatient.jar
13/08/19 12:29:54 INFO property.AppProps: using app.id: 51F6EDCB9BA70B916458070287310F04
13/08/19 12:29:54 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/08/19 12:29:54 WARN snappy.LoadSnappy: Snappy native library not loaded
13/08/19 12:29:54 INFO mapred.FileInputFormat: Total input paths to process : 1
13/08/19 12:29:54 INFO util.Version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:29:54 INFO flow.Flow: [wc] starting
13/08/19 12:29:54 INFO flow.Flow: [wc]  source: Hfs["TextDelimited[['doc_id', 'text']->[ALL]]"]["data/rain.txt"]
13/08/19 12:29:54 INFO flow.Flow: [wc]  sink: Hfs["TextDelimited[[UNKNOWN]->['token', 'count']]"]["output/wc"]
13/08/19 12:29:54 INFO flow.Flow: [wc]  parallel execution is enabled: false
13/08/19 12:29:54 INFO flow.Flow: [wc]  starting jobs: 1
13/08/19 12:29:54 INFO flow.Flow: [wc]  allocating threads: 1
13/08/19 12:29:54 INFO flow.FlowStep: [wc] starting step: (1/1) output/wc
13/08/19 12:29:54 INFO mapred.FileInputFormat: Total input paths to process : 1
13/08/19 12:29:54 INFO flow.FlowStep: [wc] submitted hadoop job: job_local317005048_0001
13/08/19 12:29:55 INFO mapred.LocalJobRunner: Waiting for map tasks
13/08/19 12:29:55 INFO mapred.LocalJobRunner: Starting task: attempt_local317005048_0001_m_000000_0
13/08/19 12:29:55 INFO util.ProcessTree: setsid exited with exit code 0
13/08/19 12:29:55 INFO mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@494eaec9
13/08/19 12:29:55 INFO io.MultiInputSplit: current split input path: file:/home/fs111/code/concurrent/Impatient/part3/data/rain.txt
13/08/19 12:29:55 INFO mapred.MapTask: Processing split: cascading.tap.hadoop.io.MultiInputSplit@15412e75
13/08/19 12:29:55 INFO mapred.MapTask: numReduceTasks: 1
13/08/19 12:29:55 INFO mapred.MapTask: io.sort.mb = 100
13/08/19 12:29:55 INFO mapred.MapTask: data buffer = 79691776/99614720
13/08/19 12:29:55 INFO mapred.MapTask: record buffer = 262144/327680
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO hadoop.FlowMapper: cascading version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:29:55 INFO hadoop.FlowMapper: child jvm opts: -Xmx200m
13/08/19 12:29:55 INFO hadoop.FlowMapper: sourcing from: Hfs["TextDelimited[['doc_id', 'text']->[ALL]]"]["data/rain.txt"]
13/08/19 12:29:55 INFO hadoop.FlowMapper: sinking to: GroupBy(wc)[by:[{1}:'token']]
13/08/19 12:29:55 INFO mapred.MapTask: Starting flush of map output
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO mapred.MapTask: Finished spill 0
13/08/19 12:29:55 INFO mapred.Task: Task:attempt_local317005048_0001_m_000000_0 is done. And is in the process of commiting
13/08/19 12:29:55 INFO mapred.LocalJobRunner: file:/home/fs111/code/concurrent/Impatient/part3/data/rain.txt:0+510
13/08/19 12:29:55 INFO mapred.Task: Task 'attempt_local317005048_0001_m_000000_0' done.
13/08/19 12:29:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local317005048_0001_m_000000_0
13/08/19 12:29:55 INFO mapred.LocalJobRunner: Map task executor complete.
13/08/19 12:29:55 INFO mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@38d30fb
13/08/19 12:29:55 INFO mapred.LocalJobRunner: 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO mapred.Merger: Merging 1 sorted segments
13/08/19 12:29:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1257 bytes
13/08/19 12:29:55 INFO mapred.LocalJobRunner: 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO hadoop.FlowReducer: cascading version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:29:55 INFO hadoop.FlowReducer: child jvm opts: -Xmx200m
13/08/19 12:29:55 INFO hadoop.FlowReducer: sourcing from: GroupBy(wc)[by:[{1}:'token']]
13/08/19 12:29:55 INFO hadoop.FlowReducer: sinking to: Hfs["TextDelimited[[UNKNOWN]->['token', 'count']]"]["output/wc"]
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:29:55 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:29:55 INFO mapred.Task: Task:attempt_local317005048_0001_r_000000_0 is done. And is in the process of commiting
13/08/19 12:29:55 INFO mapred.LocalJobRunner: 
13/08/19 12:29:55 INFO mapred.Task: Task attempt_local317005048_0001_r_000000_0 is allowed to commit now
13/08/19 12:29:55 INFO mapred.FileOutputCommitter: Saved output of task 'attempt_local317005048_0001_r_000000_0' to file:/home/fs111/code/concurrent/Impatient/part3/output/wc
13/08/19 12:29:55 INFO mapred.LocalJobRunner: reduce > reduce
13/08/19 12:29:55 INFO mapred.Task: Task 'attempt_local317005048_0001_r_000000_0' done.
13/08/19 12:30:00 INFO util.Hadoop18TapUtil: deleting temp path output/wc/_temporary
