13/08/19 12:27:24 INFO util.HadoopUtil: resolving application jar from found main method on: impatient.Main
13/08/19 12:27:24 INFO planner.HadoopPlanner: using application jar: /home/fs111/code/concurrent/Impatient/part2/./build/libs/impatient.jar
13/08/19 12:27:24 INFO property.AppProps: using app.id: 19AD740EF6D1ACFC135C0F85C25B2599
13/08/19 12:27:24 INFO util.NativeCodeLoader: Loaded the native-hadoop library
13/08/19 12:27:24 WARN snappy.LoadSnappy: Snappy native library not loaded
13/08/19 12:27:25 INFO mapred.FileInputFormat: Total input paths to process : 1
13/08/19 12:27:25 INFO util.Version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:27:25 INFO flow.Flow: [wc] starting
13/08/19 12:27:25 INFO flow.Flow: [wc]  source: Hfs["TextDelimited[['doc_id', 'text']->[ALL]]"]["data/rain.txt"]
13/08/19 12:27:25 INFO flow.Flow: [wc]  sink: Hfs["TextDelimited[[UNKNOWN]->['token', 'count']]"]["output/wc"]
13/08/19 12:27:25 INFO flow.Flow: [wc]  parallel execution is enabled: false
13/08/19 12:27:25 INFO flow.Flow: [wc]  starting jobs: 1
13/08/19 12:27:25 INFO flow.Flow: [wc]  allocating threads: 1
13/08/19 12:27:25 INFO flow.FlowStep: [wc] starting step: (1/1) output/wc
13/08/19 12:27:25 INFO mapred.FileInputFormat: Total input paths to process : 1
13/08/19 12:27:25 INFO flow.FlowStep: [wc] submitted hadoop job: job_local2072498605_0001
13/08/19 12:27:25 INFO mapred.LocalJobRunner: Waiting for map tasks
13/08/19 12:27:25 INFO mapred.LocalJobRunner: Starting task: attempt_local2072498605_0001_m_000000_0
13/08/19 12:27:25 INFO util.ProcessTree: setsid exited with exit code 0
13/08/19 12:27:25 INFO mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@1ce3570c
13/08/19 12:27:25 INFO io.MultiInputSplit: current split input path: file:/home/fs111/code/concurrent/Impatient/part2/data/rain.txt
13/08/19 12:27:25 INFO mapred.MapTask: Processing split: cascading.tap.hadoop.io.MultiInputSplit@77cfb802
13/08/19 12:27:25 INFO mapred.MapTask: numReduceTasks: 1
13/08/19 12:27:25 INFO mapred.MapTask: io.sort.mb = 100
13/08/19 12:27:25 INFO mapred.MapTask: data buffer = 79691776/99614720
13/08/19 12:27:25 INFO mapred.MapTask: record buffer = 262144/327680
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO hadoop.FlowMapper: cascading version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:27:25 INFO hadoop.FlowMapper: child jvm opts: -Xmx200m
13/08/19 12:27:25 INFO hadoop.FlowMapper: sourcing from: Hfs["TextDelimited[['doc_id', 'text']->[ALL]]"]["data/rain.txt"]
13/08/19 12:27:25 INFO hadoop.FlowMapper: sinking to: GroupBy(wc)[by:[{1}:'token']]
13/08/19 12:27:25 INFO mapred.MapTask: Starting flush of map output
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO mapred.MapTask: Finished spill 0
13/08/19 12:27:25 INFO mapred.Task: Task:attempt_local2072498605_0001_m_000000_0 is done. And is in the process of commiting
13/08/19 12:27:25 INFO mapred.LocalJobRunner: file:/home/fs111/code/concurrent/Impatient/part2/data/rain.txt:0+510
13/08/19 12:27:25 INFO mapred.Task: Task 'attempt_local2072498605_0001_m_000000_0' done.
13/08/19 12:27:25 INFO mapred.LocalJobRunner: Finishing task: attempt_local2072498605_0001_m_000000_0
13/08/19 12:27:25 INFO mapred.LocalJobRunner: Map task executor complete.
13/08/19 12:27:25 INFO mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@6bdc64a5
13/08/19 12:27:25 INFO mapred.LocalJobRunner: 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO mapred.Merger: Merging 1 sorted segments
13/08/19 12:27:25 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 1347 bytes
13/08/19 12:27:25 INFO mapred.LocalJobRunner: 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO hadoop.FlowReducer: cascading version: Concurrent, Inc - Cascading 2.1.6
13/08/19 12:27:25 INFO hadoop.FlowReducer: child jvm opts: -Xmx200m
13/08/19 12:27:25 INFO hadoop.FlowReducer: sourcing from: GroupBy(wc)[by:[{1}:'token']]
13/08/19 12:27:25 INFO hadoop.FlowReducer: sinking to: Hfs["TextDelimited[[UNKNOWN]->['token', 'count']]"]["output/wc"]
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO hadoop.TupleSerialization: using hadoop serializations from the job conf: cascading.tuple.hadoop.TupleSerialization,org.apache.hadoop.io.serializer.WritableSerialization 
13/08/19 12:27:25 INFO hadoop.TupleSerialization: adding serialization token: 127, for classname: org.apache.hadoop.io.BytesWritable
13/08/19 12:27:25 INFO mapred.Task: Task:attempt_local2072498605_0001_r_000000_0 is done. And is in the process of commiting
13/08/19 12:27:25 INFO mapred.LocalJobRunner: 
13/08/19 12:27:25 INFO mapred.Task: Task attempt_local2072498605_0001_r_000000_0 is allowed to commit now
13/08/19 12:27:25 INFO mapred.FileOutputCommitter: Saved output of task 'attempt_local2072498605_0001_r_000000_0' to file:/home/fs111/code/concurrent/Impatient/part2/output/wc
13/08/19 12:27:25 INFO mapred.LocalJobRunner: reduce > reduce
13/08/19 12:27:25 INFO mapred.Task: Task 'attempt_local2072498605_0001_r_000000_0' done.
13/08/19 12:27:30 INFO util.Hadoop18TapUtil: deleting temp path output/wc/_temporary
